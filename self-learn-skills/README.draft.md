1. 状态机视角的agentic bot：
    - agentic的探索本质上就是在一个对agent来说未知的世界里探索、收货信息的过程
    - 每一次tool调用都像是强化学习（policy based）的一个action，获得新的context（新的observation 在rl中）
2. 复杂问题的建模（理解）
    - 每次action可能是对的可能是错的。模型的context有限，又可能伴随着中间遗忘的问题。再或者agent没有“耐心”充分探索
    - 总之，复杂的问题体现为在有限的探索中，难以到达真正的目标，或者需要犯很多错巨大的试错成本才能够在长时间推理之后到达目标。
3. skill和模型自己生成skill的建模和理解：
    - 人类编写的skill，相当于在上帝视角直接在起点和终点之间划了一条边
    - 如果是这样的话，那么模型自主总结skill在这个建模中的本质就是准确定位到一次有价值的经过多次试错的探索，在一次探索的过程定位问题定义和已验证的解法
    - 如果复杂一点的问题可以保留一些与具体需求无关的helper接口可供直接调用
    - 还包括其他有用的参考资源
4. meta-skill：教模型如何写skill的skill（experience-crystallizer）
    - 目前认为需要让模型写的skill符合一定的文件结构格式，符合渐进式披露等即可。后续应该需要加上skill迭代的原则，这要和skill bank设计配合了。
    - 非常重要：必须强调，如果没有大量试错，就不要总结新的skill。需要一个形式化的判断标准。一个可能的方法是按照skill的层数和内容量做系数计算一个值，加上按照这个方法的预计step数小于原本压缩的路径step数
    - 因为实验发现，如果没有试错就总结，反而增加了读skill的成本。但也说明skill本身zero-shot学习成本较高
    - 正常情况实验，手工构造了一个较复杂的问题：恢复一个受损的文件实验结果如下：self-learn-skills/comparison_results.md。可以实现25的step节省
5. 遗留问题：
    - 目前的方案需要定位到当前session的历史记录，而agent本身并不知道自己的session
    - skill这个文件格式并不适合作为动态生成的模型经验积累文件，因为不方便做动态维护
    - 应当设计原生的渐进式探索工具和利于检测出知识是否可信的记录数据结构和存储结构
    - 也就是需要设计一个 skill bank：记录每个skill的使用情况，引导模型尝试其他方法之后丰富其中的正确和错误的example，以及设计敏锐的方式体现skill已经与实际不符，比如记录失效的案例，设计更新的机制和原则
    - 我将这个skill嵌入到了screeps游戏agent中，实际效果未知
    - 是否需要结合主动上下文压缩的训练？因为目的实际上是等价的，可以互相借鉴。例如目前的skill不管如何描述，都难以让模型真正主动调用。
6. 其他未来可以做的
    - 无需训练的蒸馏：高级模型总结skill，就像写武林秘籍一样，虽然无法达到高级模型的水平，但能实现80%的水平。
    - 无训练的领域微调：如果能实现高效的更新协议，基于这个系统可以实现个性化的skill bank，few-shot的学习用户习惯、工作内容、工作背景等信息而不需要领域微调
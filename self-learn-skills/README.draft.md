1. 状态机视角的agentic bot：
    - agentic的探索本质上就是在一个对agent来说未知的世界里探索、收货信息的过程
    - 每一次tool调用都像是强化学习（policy based）的一个action，获得新的context（新的observation 在rl中）
2. 复杂问题的建模（理解）
    - 每次action可能是对的可能是错的。模型的context有限，又可能伴随着中间遗忘的问题。再或者agent没有“耐心”充分探索
    - 总之，复杂的问题体现为在有限的探索中，难以到达真正的目标，或者需要犯很多错巨大的试错成本才能够在长时间推理之后到达目标。
3. skill和模型自己生成skill的建模和理解：
    - 人类编写的skill，相当于在上帝视角直接在起点和终点之间划了一条边
    - 如果是这样的话，那么模型自主总结skill在这个建模中的本质就是准确定位到一次有价值的经过多次试错的探索，在一次探索的过程定位问题定义和已验证的解法
    - 如果复杂一点的问题可以保留一些与具体需求无关的helper接口可供直接调用
    - 还包括其他有用的参考资源
4. meta-skill：教模型如何写skill的skill（experience-crystallizer）
    - 目前认为需要让模型写的skill符合一定的文件结构格式，符合渐进式披露等即可
    - 非常重要：必须强调，如果没有大量试错，就不要总结心得skill
    因为实验发现，如果没有试错就总结，反而增加了读skill的成本
    - 正常情况实验，手工构造了一个较复杂的问题：恢复一个受损的文件实验结果如下：self-learn-skills/comparison_results.md。可以实现25的step节省
5. 遗留问题：
    - 目前的方案需要定位到当前session的历史记录，而agent本身并不知道自己的session
    - skill这个文件格式并不适合作为动态生成的模型经验积累文件，因为不方便做动态维护
    - 我将这个skill嵌入到了screeps游戏agent中，实际效果未知
    - 是否需要结合主动上下文压缩的训练？因为目的实际上是等价的，可以互相借鉴
